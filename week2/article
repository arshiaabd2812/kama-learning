
## ✨ مقالات پیشنهادی با خلاصه ساده و لینک

### 1. *FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting*  
*نویسندگان:* Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, Rong Jin  
*محل انتشار / سال:* ICML (Conference on Machine Learning), 2022  
*لینک:* [PMLR/ICML](https://proceedings.mlr.press/v162/zhou22g.html) • [arXiv](https://arxiv.org/abs/2201.12740) 0  
*Citation:* 2929 1  
*Impact Factor:* — (کنفرانس)  
*خلاصه به زبان ساده:*  
با ترکیبِ تجزیه‌ی روند/فصلی و تقویتِ حوزه‌ی فرکانس، یک ترنسفورمر می‌سازد که هم سریع‌تر است و هم الگوهای بلندمدت را بهتر می‌بیند. نتیجه: پیش‌بینی دقیق‌تر در افق‌های طولانی. 2  
*دیتاست / داده‌ها:* Electricity, Traffic, Exchange-Rate, Weather, ETT, ILI (بنچمارک‌های مرسوم LTSF) 3  
*پلتفرم اجرا:* PyTorch (رایج)  
*کد / گیت‌هاب:* [github.com/MAZiqing/FEDformer](https://github.com/MAZiqing/FEDformer) 4

---

### 2. *PatchTST: A Time Series is Worth 64 Words — Long-term Forecasting with Transformers*  
*نویسندگان:* Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, Jayant Kalagnanam  
*محل انتشار / سال:* ICLR, 2023  
*لینک:* [arXiv](https://arxiv.org/abs/2211.14730) • [GitHub](https://github.com/yuqinie98/PatchTST) 5  
*Citation:* 2915 6  
*Impact Factor:* — (کنفرانس)  
*خلاصه به زبان ساده:*  
سری زمانی را مثل «کلمات» به وصله‌ها (patch) می‌شکند و هر کانال را جداگانه مدل می‌کند؛ هم حافظه/محاسبات کمتر می‌شود، هم افق‌بلندتر دیده می‌شود و دقت بالا می‌رود. 7  
*دیتاست / داده‌ها:* همان بنچمارک‌های LTSF (ETT, Electricity, Traffic, Exchange, Weather, ILI) 8  
*پلتفرم اجرا:* PyTorch  
*کد / گیت‌هاب:* [github.com/yuqinie98/PatchTST](https://github.com/yuqinie98/PatchTST) 9

---

### 3. *TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis*  
*نویسندگان:* Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, Mingsheng Long  
*محل انتشار / سال:* ICLR, 2023  
*لینک:* [OpenReview](https://openreview.net/forum?id=ju_Uqw384Oq) • [GitHub](https://github.com/thuml/TimesNet) 10  
*Citation:* 2261 11  
*Impact Factor:* — (کنفرانس)  
*خلاصه به زبان ساده:*  
به‌جای مدل‌کردن مستقیم 1بعدی، الگوهای زمانی را به نگاشت‌های 2بعدی تبدیل می‌کند تا تغییرات درون‌دوره‌ای/میان‌دوره‌ای بهتر دیده شوند؛ یک ستون‌فقرات عمومی برای پیش‌بینی، تکمیل، طبقه‌بندی و… 12  
*دیتاست / داده‌ها:* مجموعه‌های استاندارد LTSF و سایر وظایف عمومی سری‌زمانی 13  
*پلتفرم اجرا:* PyTorch  
*کد / گیت‌هاب:* [github.com/thuml/TimesNet](https://github.com/thuml/TimesNet) 14

---

### 4. *iTransformer: Inverted Transformers Are Effective for Time Series Forecasting*  
*نویسندگان:* Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, Mingsheng Long  
*محل انتشار / سال:* ICLR, 2024  
*لینک:* [arXiv](https://arxiv.org/abs/2310.06625) • [GitHub](https://github.com/thuml/iTransformer) 15  
*Citation:* 1828 16  
*Impact Factor:* — (کنفرانس)  
*خلاصه به زبان ساده:*  
به‌جای توکن‌کردن «زمان»، ابعادِ «ویژگی/سری‌ها» را توکن می‌گیرد؛ این وارونگی، همبستگی بین‌متغیره را بهتر می‌گیرد و در افق‌های طولانی پایدارتر است. 17  
*دیتاست / داده‌ها:* بنچمارک‌های مرسوم LTSF (ETT, Electricity, …) 18  
*پلتفرم اجرا:* PyTorch  
*کد / گیت‌هاب:* [github.com/thuml/iTransformer](https://github.com/thuml/iTransformer) 19

---

### 5. *Are Transformers Effective for Time Series Forecasting? (LTSF-Linear / DLinear)*  
*نویسندگان:* Ailing Zeng, Muxi Chen, Lei Zhang, Qiang Xu  
*محل انتشار / سال:* AAAI, 2023  
*لینک:* [AAAI (dl.acm.org)](https://dl.acm.org/doi/10.1609/AAAI.V37I9.26317) • [arXiv](https://arxiv.org/abs/2205.13504) • [Code (LTSF-Linear/DLinear)](https://github.com/cure-lab/LTSF-Linear) 20  
*Citation:* 3460 21  
*Impact Factor:* — (کنفرانس)  
*خلاصه به زبان ساده:*  
یک خط مبنا‌ی خطی بسیار ساده معرفی می‌کند که روی خیلی از بنچمارک‌ها از ترنسفورمرهای پیچیده بهتر می‌زند؛ نتیجه: ضرورت بازنگری در ارزیابی و معیارهای LTSF. 22  
*دیتاست / داده‌ها:* ETT, Electricity, Traffic, Weather, Exchange, ILI 23  
*پلتفرم اجرا:* PyTorch  
*کد / گیت‌هاب:* (LTSF-Linear/DLinear) در لینک بالا

---

## 📊 جدول خلاصه مقالات

| # | نوع | سال | محل انتشار | تمرکز اصلی | دیتاست | کد | Citation |
|---|-----|-----|------------|------------|--------|-----|----------|
| 1 | پژوهشی | 2022 | ICML | ترنسفورمر با تقویت فرکانسی و تجزیه روند/فصل | ETT, Elec., Traffic, Weather, Exchange, ILI | [FEDformer](https://github.com/MAZiqing/FEDformer) | 2929 |
| 2 | پژوهشی | 2023 | ICLR | پچ‌کردن سری زمانی + استقلال کانال‌ها | همان بنچمارک‌های LTSF | [PatchTST](https://github.com/yuqinie98/PatchTST) | 2915 |
| 3 | پژوهشی | 2023 | ICLR | نگاشت 2بعدی تغییرات زمانی (ستون‌فقرات عمومی) | مجموعه‌های عمومی LTSF و فراتر | [TimesNet](https://github.com/thuml/TimesNet) | 2261 |
| 4 | پژوهشی | 2024 | ICLR | وارونگی ابعاد (توکنِ متغیرها) برای همبستگی بین‌متغیره | بنچمارک‌های مرسوم LTSF | [iTransformer](https://github.com/thuml/iTransformer) | 1828 |
| 5 | پژوهشی | 2023 | AAAI | خط‌مبنای خطی ساده (بازاندیشی در ارزیابی LTSF) | ETT, Elec., Traffic, Weather, Exchange, ILI | [LTSF-Linear](https://github.com/cure-lab/LTSF-Linear) | 3460 |

---

### 🧠 چرا این پنج‌تا «همگرا» هستند؟
همه روی یک هدف مشترک‌اند: *پیش‌بینی بلندمدت سری‌های زمانی*. سه رویکرد ترنسفورمری مختلف (تقویت فرکانس، پچ‌کردن، وارونگی ابعاد) + یک ستون‌فقرات عمومی (TimesNet) و یک خط‌مبنای خطی قوی (DLinear/LTSF-Linear) کنار هم، هم عمق فنی می‌دهند هم چارچوب مقایسه‌ای منصفانه برای پروژه‌ات.

